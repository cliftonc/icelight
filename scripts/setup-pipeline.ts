#!/usr/bin/env tsx
/**
 * Setup script for cdpflare infrastructure
 * Creates R2 bucket, Data Catalog, Stream, Sink, and Pipeline
 *
 * Usage: pnpm launch
 *
 * Environment variables (optional, defaults provided):
 * - BUCKET_NAME: R2 bucket name (default: cdpflare-data)
 * - STREAM_NAME: Stream name (default: cdpflare_events_stream)
 * - SINK_NAME: Sink name (default: cdpflare_events_sink)
 * - PIPELINE_NAME: Pipeline name (default: cdpflare_events_pipeline)
 */

import { execSync, spawnSync } from 'child_process';
import { existsSync, readFileSync, writeFileSync } from 'fs';
import { join, dirname } from 'path';
import { fileURLToPath } from 'url';
import { createInterface } from 'readline';

const __dirname = dirname(fileURLToPath(import.meta.url));

// Default project name - all resource names are derived from this
const defaultProjectName = process.env.PROJECT_NAME || 'cdpflare';

// Configuration - populated after prompting user
interface Config {
  bucketName: string;
  streamName: string;
  sinkName: string;
  pipelineName: string;
}
let config: Config;

// Colors for output
const colors = {
  reset: '\x1b[0m',
  green: '\x1b[32m',
  yellow: '\x1b[33m',
  red: '\x1b[31m',
  cyan: '\x1b[36m',
  bold: '\x1b[1m',
  dim: '\x1b[2m',
};

function log(message: string, color: keyof typeof colors = 'reset') {
  console.log(`${colors[color]}${message}${colors.reset}`);
}

function runQuiet(command: string): string | null {
  try {
    return execSync(command, {
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });
  } catch {
    return null;
  }
}

function runCommand(command: string, _description?: string): boolean {
  log(`  ${colors.dim}$ ${command}${colors.reset}`);
  try {
    execSync(command, {
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });
    return true;
  } catch (error) {
    const err = error as { stderr?: string; message?: string };
    const stderr = err.stderr || err.message || 'Unknown error';
    log(`  ✗ Failed: ${stderr}`, 'red');
    return false;
  }
}

function getSchemaPath(): string {
  const schemaPath = join(__dirname, '..', 'templates', 'schema.events.json');
  if (!existsSync(schemaPath)) {
    throw new Error(`Schema file not found: ${schemaPath}`);
  }
  return schemaPath;
}

function prompt(question: string): Promise<string> {
  const rl = createInterface({
    input: process.stdin,
    output: process.stdout,
  });
  return new Promise((resolve) => {
    rl.question(question, (answer) => {
      rl.close();
      resolve(answer.trim());
    });
  });
}

/**
 * Strip JSON comments and trailing commas to parse JSONC
 */
function parseJsonc(content: string): unknown {
  // Remove single-line comments
  let stripped = content.replace(/\/\/.*$/gm, '');
  // Remove multi-line comments
  stripped = stripped.replace(/\/\*[\s\S]*?\*\//g, '');
  // Remove trailing commas before } or ]
  stripped = stripped.replace(/,(\s*[}\]])/g, '$1');
  return JSON.parse(stripped);
}

/**
 * Create wrangler.local.jsonc for query-api worker
 */
function createQueryApiLocalConfig(warehouseName: string): boolean {
  const basePath = join(__dirname, '..', 'workers', 'query-api', 'wrangler.jsonc');
  const localPath = join(__dirname, '..', 'workers', 'query-api', 'wrangler.local.jsonc');

  if (!existsSync(basePath)) {
    log(`  ⚠ Query API config not found: ${basePath}`, 'yellow');
    return false;
  }

  try {
    const baseContent = readFileSync(basePath, 'utf-8');
    const config = parseJsonc(baseContent) as Record<string, unknown>;

    // Add or update WAREHOUSE_NAME in vars
    const vars = (config.vars as Record<string, unknown>) || {};
    vars.WAREHOUSE_NAME = warehouseName;
    config.vars = vars;

    // Write local config with comment header
    const localContent = `// Local wrangler config - DO NOT COMMIT
// Generated by: pnpm launch
// Contains environment-specific values for your Cloudflare account
${JSON.stringify(config, null, 2)}
`;

    writeFileSync(localPath, localContent);
    log(`  ✓ Created wrangler.local.jsonc with WAREHOUSE_NAME`, 'green');
    return true;
  } catch (error) {
    log(`  ✗ Failed to create local config: ${error}`, 'red');
    return false;
  }
}

/**
 * Create wrangler.local.jsonc for event-ingest worker
 */
function createEventIngestLocalConfig(streamId: string): boolean {
  const basePath = join(__dirname, '..', 'workers', 'event-ingest', 'wrangler.jsonc');
  const localPath = join(__dirname, '..', 'workers', 'event-ingest', 'wrangler.local.jsonc');

  if (!existsSync(basePath)) {
    log(`  ⚠ Event Ingest config not found: ${basePath}`, 'yellow');
    return false;
  }

  try {
    const baseContent = readFileSync(basePath, 'utf-8');
    const config = parseJsonc(baseContent) as Record<string, unknown>;

    // Add pipeline binding
    config.pipelines = [
      {
        pipeline: streamId,
        binding: 'PIPELINE',
      },
    ];

    // Write local config with comment header
    const localContent = `// Local wrangler config - DO NOT COMMIT
// Generated by: pnpm launch
// Contains environment-specific values for your Cloudflare account
${JSON.stringify(config, null, 2)}
`;

    writeFileSync(localPath, localContent);
    log(`  ✓ Created wrangler.local.jsonc with pipeline binding`, 'green');
    return true;
  } catch (error) {
    log(`  ✗ Failed to create local config: ${error}`, 'red');
    return false;
  }
}

function setSecret(name: string, value: string, configPath: string): boolean {
  try {
    // Use spawn with input to set secret non-interactively
    const result = spawnSync('npx', ['wrangler', 'secret', 'put', name, '--config', configPath], {
      input: value,
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });

    if (result.status === 0) {
      log(`  ✓ Set ${name} secret`, 'green');
      return true;
    } else {
      log(`  ✗ Failed to set ${name}: ${result.stderr}`, 'red');
      return false;
    }
  } catch (error) {
    log(`  ✗ Failed to set ${name}: ${error}`, 'red');
    return false;
  }
}

interface SecretStatus {
  CF_ACCOUNT_ID: boolean;
  CF_API_TOKEN: boolean;
}

function checkSecrets(configPath: string): SecretStatus {
  const status: SecretStatus = {
    CF_ACCOUNT_ID: false,
    CF_API_TOKEN: false,
  };

  try {
    const output = execSync(`npx wrangler secret list --config "${configPath}"`, {
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });

    if (output.includes('CF_ACCOUNT_ID')) {
      status.CF_ACCOUNT_ID = true;
    }
    if (output.includes('CF_API_TOKEN')) {
      status.CF_API_TOKEN = true;
    }
  } catch {
    // Secrets list may fail if worker not deployed yet - that's ok
  }

  return status;
}

// Resource checking functions
interface ExistingResources {
  bucket: boolean;
  catalogEnabled: boolean;
  stream: { exists: boolean; id: string | null };
  sink: { exists: boolean; id: string | null };
  pipeline: { exists: boolean; id: string | null };
}

function checkExistingResources(): ExistingResources {
  const resources: ExistingResources = {
    bucket: false,
    catalogEnabled: false,
    stream: { exists: false, id: null },
    sink: { exists: false, id: null },
    pipeline: { exists: false, id: null },
  };

  // Check R2 bucket
  const bucketsOutput = runQuiet('npx wrangler r2 bucket list');
  if (bucketsOutput && bucketsOutput.includes(config.bucketName)) {
    resources.bucket = true;

    // Check if catalog is enabled (status shows as "active")
    const catalogOutput = runQuiet(`npx wrangler r2 bucket catalog get ${config.bucketName}`);
    if (catalogOutput && (catalogOutput.includes('active') || catalogOutput.includes('enabled'))) {
      resources.catalogEnabled = true;
    }
  }

  // Check streams
  const streamsOutput = runQuiet('npx wrangler pipelines streams list');
  if (streamsOutput) {
    const lines = streamsOutput.split('\n');
    for (const line of lines) {
      if (line.includes(config.streamName)) {
        resources.stream.exists = true;
        const idMatch = line.match(/([a-f0-9]{32})/i);
        if (idMatch) {
          resources.stream.id = idMatch[1];
        }
        break;
      }
    }
  }

  // Check sinks
  const sinksOutput = runQuiet('npx wrangler pipelines sinks list');
  if (sinksOutput) {
    const lines = sinksOutput.split('\n');
    for (const line of lines) {
      if (line.includes(config.sinkName)) {
        resources.sink.exists = true;
        const idMatch = line.match(/([a-f0-9]{32})/i);
        if (idMatch) {
          resources.sink.id = idMatch[1];
        }
        break;
      }
    }
  }

  // Check pipelines
  const pipelinesOutput = runQuiet('npx wrangler pipelines list');
  if (pipelinesOutput) {
    const lines = pipelinesOutput.split('\n');
    for (const line of lines) {
      if (line.includes(config.pipelineName)) {
        resources.pipeline.exists = true;
        const idMatch = line.match(/([a-f0-9]{32})/i);
        if (idMatch) {
          resources.pipeline.id = idMatch[1];
        }
        break;
      }
    }
  }

  return resources;
}

interface AuthInfo {
  authenticated: boolean;
  email?: string;
  accountId?: string;
}

function checkWranglerAuth(): AuthInfo {
  log('\n> Checking Cloudflare authentication...', 'cyan');
  try {
    const output = execSync('npx wrangler whoami', {
      encoding: 'utf-8',
      stdio: ['pipe', 'pipe', 'pipe'],
    });

    if (output.includes('You are not authenticated')) {
      return { authenticated: false };
    }

    const result: AuthInfo = { authenticated: true };

    const emailMatch = output.match(/associated with the email ([^\s]+)/);
    if (emailMatch) {
      result.email = emailMatch[1];
      log(`  ✓ Logged in as: ${emailMatch[1]}`, 'green');
    } else {
      log(`  ✓ Authenticated with Cloudflare`, 'green');
    }

    // Try to extract account ID
    const accountMatch = output.match(/Account ID[:\s]+([a-f0-9]{32})/i);
    if (accountMatch) {
      result.accountId = accountMatch[1];
    } else {
      // Try alternative: get from wrangler config or API
      const accountsOutput = runQuiet('npx wrangler whoami --account');
      if (accountsOutput) {
        const idMatch = accountsOutput.match(/([a-f0-9]{32})/i);
        if (idMatch) {
          result.accountId = idMatch[1];
        }
      }
    }

    if (result.accountId) {
      log(`  ✓ Account ID: ${result.accountId}`, 'green');
    }

    return result;
  } catch {
    return { authenticated: false };
  }
}

async function main() {
  log('\n╔════════════════════════════════════════════════════════════╗', 'cyan');
  log('║           cdpflare Infrastructure Setup                     ║', 'cyan');
  log('╚════════════════════════════════════════════════════════════╝', 'cyan');

  // Prompt for project name first
  log('\n┌────────────────────────────────────────────────────────────┐', 'cyan');
  log('│                    Configuration                           │', 'cyan');
  log('└────────────────────────────────────────────────────────────┘', 'cyan');
  log('\n  All resource names are derived from the project name.', 'reset');
  const projectInput = await prompt(`\n  Project name [${defaultProjectName}]: `);
  const projectName = projectInput || defaultProjectName;

  // Derive all names from project name
  // Bucket uses hyphens (R2 requirement), pipeline resources use underscores (stream requirement)
  const underscoreName = projectName.replace(/-/g, '_');
  config = {
    bucketName: `${projectName}-data`,
    streamName: `${underscoreName}_events_stream`,
    sinkName: `${underscoreName}_events_sink`,
    pipelineName: `${underscoreName}_events_pipeline`,
  };

  log(`\n  Using configuration:`, 'cyan');
  log(`    Bucket:   ${config.bucketName}`, 'reset');
  log(`    Stream:   ${config.streamName}`, 'reset');
  log(`    Sink:     ${config.sinkName}`, 'reset');
  log(`    Pipeline: ${config.pipelineName}`, 'reset');

  // Check authentication first
  const authInfo = checkWranglerAuth();
  if (!authInfo.authenticated) {
    log('\n  ✗ Not logged in to Cloudflare', 'red');
    log('\n  Please run the following command to authenticate:', 'yellow');
    log('    npx wrangler login', 'cyan');
    log('\n  This will open a browser window to authorize wrangler.', 'yellow');
    log('  After logging in, run this setup script again.\n', 'yellow');
    process.exit(1);
  }

  log('\n> Checking existing resources...', 'cyan');
  const existing = checkExistingResources();

  const schemaPath = getSchemaPath();

  // Show what exists and what needs to be created
  log('\n┌────────────────────────────────────────────────────────────┐', 'cyan');
  log('│                    Resource Status                          │', 'cyan');
  log('└────────────────────────────────────────────────────────────┘', 'cyan');

  log(`\n  R2 Bucket (${config.bucketName}):`, 'reset');
  if (existing.bucket) {
    log(`    ✓ Exists`, 'green');
    log(`    ${existing.catalogEnabled ? '✓ Data Catalog enabled' : '○ Data Catalog not enabled'}`,
      existing.catalogEnabled ? 'green' : 'yellow');
  } else {
    log(`    ○ Not created`, 'yellow');
  }

  log(`\n  Stream (${config.streamName}):`, 'reset');
  if (existing.stream.exists) {
    log(`    ✓ Exists (ID: ${existing.stream.id})`, 'green');
  } else {
    log(`    ○ Not created`, 'yellow');
  }

  log(`\n  Sink (${config.sinkName}):`, 'reset');
  if (existing.sink.exists) {
    log(`    ✓ Exists (ID: ${existing.sink.id})`, 'green');
  } else {
    log(`    ○ Not created`, 'yellow');
  }

  log(`\n  Pipeline (${config.pipelineName}):`, 'reset');
  if (existing.pipeline.exists) {
    log(`    ✓ Exists (ID: ${existing.pipeline.id})`, 'green');
  } else {
    log(`    ○ Not created`, 'yellow');
  }

  // Determine what needs to be created
  const needsBucket = !existing.bucket;
  const needsCatalog = !existing.catalogEnabled;
  const needsStream = !existing.stream.exists;
  const needsSink = !existing.sink.exists;
  const needsPipeline = !existing.pipeline.exists;

  const allExist = !needsBucket && !needsCatalog && !needsStream && !needsSink && !needsPipeline;

  // If we need to create sink, we need an API token for the data catalog
  let catalogToken = '';
  if (needsSink) {
    log('\n┌────────────────────────────────────────────────────────────┐', 'yellow');
    log('│              API Token Required for Data Catalog           │', 'yellow');
    log('└────────────────────────────────────────────────────────────┘', 'yellow');
    log('\n  The r2-data-catalog sink requires an API token with permissions:', 'reset');
    log('    • Account → Workers R2 Storage → Edit', 'reset');
    log('    • Account → Workers R2 Data Catalog → Edit', 'reset');
    log('    • Account → Workers R2 SQL → Read', 'reset');
    log('\n  Create a token at: https://dash.cloudflare.com/profile/api-tokens', 'cyan');
    log('\n  Paste your API token below:', 'yellow');
    catalogToken = await prompt('  API Token: ');
    if (!catalogToken) {
      log('\n  ✗ API token is required to create the data catalog sink.', 'red');
      process.exit(1);
    }
  }

  if (allExist) {
    log('\n> All resources already exist!', 'green');
  } else {
    log('\n> Creating missing resources...', 'cyan');

    // Step 1: Create R2 bucket if needed
    if (needsBucket) {
      log('\n  Creating R2 bucket...', 'cyan');
      if (!runCommand(`npx wrangler r2 bucket create ${config.bucketName}`, 'Create bucket')) {
        log('\nFailed to create R2 bucket. Aborting.', 'red');
        process.exit(1);
      }
      log(`    ✓ Created ${config.bucketName}`, 'green');
    }

    // Step 2: Enable Data Catalog if needed
    if (needsCatalog) {
      log('\n  Enabling Data Catalog...', 'cyan');
      if (!runCommand(`npx wrangler r2 bucket catalog enable ${config.bucketName}`, 'Enable catalog')) {
        log('\nFailed to enable Data Catalog. Aborting.', 'red');
        process.exit(1);
      }
      log(`    ✓ Data Catalog enabled`, 'green');
    }

    // Step 3: Create stream if needed
    if (needsStream) {
      log('\n  Creating stream...', 'cyan');
      const streamCmd = `npx wrangler pipelines streams create ${config.streamName} ` +
        `--schema-file "${schemaPath}" ` +
        `--http-enabled true ` +
        `--http-auth false`;
      if (!runCommand(streamCmd, 'Create stream')) {
        log('\nFailed to create stream. Aborting.', 'red');
        process.exit(1);
      }
      log(`    ✓ Created ${config.streamName}`, 'green');
    }

    // Step 4: Create sink if needed
    if (needsSink) {
      log('\n  Creating sink...', 'cyan');
      // Use r2-data-catalog sink type for Iceberg tables queryable by R2 SQL
      const sinkCmd = `npx wrangler pipelines sinks create ${config.sinkName} ` +
        `--type r2-data-catalog ` +
        `--bucket ${config.bucketName} ` +
        `--namespace analytics ` +
        `--table events ` +
        `--catalog-token "${catalogToken}"`;
      if (!runCommand(sinkCmd, 'Create sink')) {
        log('\nFailed to create sink. Aborting.', 'red');
        process.exit(1);
      }
      log(`    ✓ Created ${config.sinkName}`, 'green');
    }

    // Step 5: Create pipeline if needed
    if (needsPipeline) {
      log('\n  Creating pipeline...', 'cyan');
      const pipelineCmd = `npx wrangler pipelines create ${config.pipelineName} ` +
        `--sql "INSERT INTO ${config.sinkName} SELECT * FROM ${config.streamName}"`;
      if (!runCommand(pipelineCmd, 'Create pipeline')) {
        log('\nFailed to create pipeline. Aborting.', 'red');
        process.exit(1);
      }
      log(`    ✓ Created ${config.pipelineName}`, 'green');
    }
  }

  // Refresh resource info after any creations
  log('\n> Fetching final resource details...', 'cyan');
  const finalResources = checkExistingResources();

  // Success!
  log('\n╔════════════════════════════════════════════════════════════╗', 'green');
  log('║           Setup Complete!                                   ║', 'green');
  log('╚════════════════════════════════════════════════════════════╝', 'green');

  // Show resource summary
  log('\n┌────────────────────────────────────────────────────────────┐', 'cyan');
  log('│                    Resource Summary                         │', 'cyan');
  log('└────────────────────────────────────────────────────────────┘', 'cyan');

  log('\n  R2 Bucket:', 'cyan');
  log(`    Name: ${config.bucketName}`, 'reset');

  log('\n  Stream:', 'cyan');
  log(`    Name: ${config.streamName}`, 'reset');
  if (finalResources.stream.id) {
    log(`    ID:   ${colors.bold}${finalResources.stream.id}${colors.reset}`, 'green');
    log(`    HTTP: https://${finalResources.stream.id}.ingest.cloudflare.com`, 'reset');
  }

  log('\n  Sink:', 'cyan');
  log(`    Name: ${config.sinkName}`, 'reset');
  if (finalResources.sink.id) {
    log(`    ID:   ${finalResources.sink.id}`, 'reset');
  }
  log(`    Path: ${config.bucketName}/events/`, 'reset');

  log('\n  Pipeline:', 'cyan');
  log(`    Name: ${config.pipelineName}`, 'reset');
  if (finalResources.pipeline.id) {
    log(`    ID:   ${finalResources.pipeline.id}`, 'reset');
  }
  log(`    SQL:  INSERT INTO ${config.sinkName} SELECT * FROM ${config.streamName}`, 'dim');

  // Create event-ingest local config with pipeline binding
  if (finalResources.stream.id) {
    log('\n┌────────────────────────────────────────────────────────────┐', 'cyan');
    log('│            Event Ingest Worker Configuration               │', 'cyan');
    log('└────────────────────────────────────────────────────────────┘', 'cyan');

    createEventIngestLocalConfig(finalResources.stream.id);
  } else {
    log('\n  ⚠ Could not fetch Stream ID automatically.', 'yellow');
    log('  Run: npx wrangler pipelines streams list', 'yellow');
    log('  Then manually create workers/event-ingest/wrangler.local.jsonc', 'yellow');
  }

  log('\n┌────────────────────────────────────────────────────────────┐', 'cyan');
  log('│                      Next Steps                            │', 'cyan');
  log('└────────────────────────────────────────────────────────────┘', 'cyan');
  log('\n  1. Deploy: pnpm deploy:ingest');
  log('  2. Test:');
  log(`     curl -X POST https://cdpflare-event-ingest.YOUR-SUBDOMAIN.workers.dev/v1/track \\`);
  log(`       -H "Content-Type: application/json" \\`);
  log(`       -d '{"userId":"test","event":"Test Event"}'`);

  // Query API configuration
  log('\n┌────────────────────────────────────────────────────────────┐', 'cyan');
  log('│              Query API Configuration (Optional)            │', 'cyan');
  log('└────────────────────────────────────────────────────────────┘', 'cyan');

  if (!authInfo.accountId) {
    log('\n  ⚠ Could not detect Account ID automatically.', 'yellow');
    log('  To configure Query API manually, see README.md\n', 'yellow');
    return;
  }

  log('\n  The Query API lets you query your analytics data via HTTP.');
  log('  Would you like to configure it now?\n');

  const setupQuery = await prompt('  Configure Query API? (y/N): ');

  if (setupQuery.toLowerCase() !== 'y') {
    log('\n  Skipped Query API setup. Run pnpm launch again to configure later.\n', 'yellow');
    return;
  }

  log('\n  Configuring Query API...', 'cyan');

  // Step 1: Create local config with bucket name (R2 SQL uses bucket name as warehouse)
  log('\n  1. Creating local config...', 'cyan');
  createQueryApiLocalConfig(config.bucketName);

  // Check existing secrets (use base config for secrets command)
  const baseConfigPath = join(__dirname, '..', 'workers', 'query-api', 'wrangler.jsonc');
  const secrets = checkSecrets(baseConfigPath);

  // Step 2: Set CF_ACCOUNT_ID secret (if not already set)
  log('\n  2. Setting CF_ACCOUNT_ID secret...', 'cyan');
  if (secrets.CF_ACCOUNT_ID) {
    log(`  ✓ CF_ACCOUNT_ID already configured`, 'green');
  } else {
    setSecret('CF_ACCOUNT_ID', authInfo.accountId, baseConfigPath);
  }

  // Step 3: Set CF_API_TOKEN secret (if not already set)
  log('\n  3. Setting CF_API_TOKEN secret...', 'cyan');
  if (secrets.CF_API_TOKEN) {
    log(`  ✓ CF_API_TOKEN already configured`, 'green');
  } else if (catalogToken) {
    // Reuse the token from sink creation
    setSecret('CF_API_TOKEN', catalogToken, baseConfigPath);
  } else {
    log('\n  API Token required for R2 SQL access.', 'yellow');
    log('\n  Create an API token at:', 'reset');
    log('    https://dash.cloudflare.com/profile/api-tokens', 'cyan');
    log('\n  Required permissions:', 'reset');
    log('    • Account → Workers R2 Storage → Edit', 'reset');
    log('    • Account → Workers R2 Data Catalog → Edit', 'reset');
    log('    • Account → Workers R2 SQL → Read', 'reset');
    log('\n  Paste your API token below:', 'yellow');

    const apiToken = await prompt('  API Token: ');

    if (apiToken) {
      setSecret('CF_API_TOKEN', apiToken, baseConfigPath);
    } else {
      log('\n  ⚠ No API token provided. Set it manually:', 'yellow');
      log('    npx wrangler secret put CF_API_TOKEN --config workers/query-api/wrangler.jsonc', 'yellow');
    }
  }

  log('\n┌────────────────────────────────────────────────────────────┐', 'green');
  log('│              Query API Configuration Complete!             │', 'green');
  log('└────────────────────────────────────────────────────────────┘', 'green');

  log('\n  Deploy with: pnpm deploy:query');
  log('\n  Test with:');
  log('    curl https://cdpflare-query-api.YOUR-SUBDOMAIN.workers.dev/health');

  log('\n  See README.md for full documentation.\n');
}

main().catch((error) => {
  log(`\nSetup failed: ${error.message}`, 'red');
  process.exit(1);
});
